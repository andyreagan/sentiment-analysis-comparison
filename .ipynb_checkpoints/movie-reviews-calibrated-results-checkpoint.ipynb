{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/andyreagan/tools/python/labMTsimple/\")\n",
    "from labMTsimple.speedy import *\n",
    "from labMTsimple.storyLab import *\n",
    "\n",
    "import re\n",
    "import codecs\n",
    "from os import listdir,mkdir\n",
    "from os.path import isfile,isdir\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import rc,rcParams\n",
    "rc(\"xtick\", labelsize=8)\n",
    "rc(\"ytick\", labelsize=8)\n",
    "rc(\"font\",**{\"family\":\"serif\",\"serif\":[\"cmr10\"]})\n",
    "# rc(\"text\", usetex=True)\n",
    "figwidth_onecol = 8.5\n",
    "figwidth_twocol = figwidth_onecol/2\n",
    "\n",
    "import numpy as np\n",
    "from json import loads\n",
    "import csv\n",
    "from datetime import datetime,timedelta\n",
    "import pickle\n",
    "\n",
    "from subprocess import call\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "error_logging = True\n",
    "sys.path.append(\"/Users/andyreagan/tools/python/kitchentable\")\n",
    "from dogtoys import *\n",
    "\n",
    "\n",
    "\n",
    "test_name = \"LabMT-ANEW-LIWC-MPQA-Liu-WK-long\"\n",
    "allLengths = [1,   2,   3,   5,   7,   10, 15,  25, 40, 60, 80,100,150,250,400,600,900,1000]\n",
    "allSamples = [1000,2000,1500,1500,1000,900,750,600,500,250,100, 75, 75, 55, 40, 25, 15,   1]\n",
    "allSamples[0] = 1000\n",
    "allSamples[-1] = 1\n",
    "\n",
    "\n",
    "middle=100\n",
    "test_name = \"LabMT-ANEW-LIWC-MPQA-Liu-WK-{}\".format(middle)\n",
    "allLengths = [1,   2,   3,   5,   7,   10, 15,  25, 40, 60, 80,100,150,250,400,600,900,1000]\n",
    "allSamples = [middle for i in range(len(allLengths))]\n",
    "allSamples[0] = 1000\n",
    "allSamples[-1] = 1\n",
    "\n",
    "\n",
    "test_name = \"all-test\"\n",
    "allLengths = [1,   2,   3,   5,   7,   10, 15,  25, 40, 60, 80,100,150,250,400,600,900,1000]\n",
    "# allSamples = [1000,2000,1500,1500,1000,900,750,600,500,250,100, 75, 75, 55, 40, 25, 15,   1]\n",
    "allSamples = [1 for i in range(len(allLengths))]\n",
    "allSamples[0] = 1000\n",
    "allSamples[-1] = 1\n",
    "\n",
    "test_name = \"all-singles\"\n",
    "allLengths = [1]\n",
    "allSamples = [1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sampleReviewsDict(numReviews,numSamples,filelist,wordsRE,prefix,test=\"LabMT-ANEW-LIWC-MPQA-Liu-WK\"):\n",
    "    \"\"\"Sample from all of the review.\"\"\"\n",
    "    if numReviews == 1:\n",
    "        choose_randomly = False\n",
    "    else:\n",
    "        choose_randomly = True\n",
    "\n",
    "    scores = [[0.0 for i in range(numSamples)] for j in range(len(wordsRE))]\n",
    "    for i in range(numSamples):\n",
    "        # print(\"on sample {0}\".format(i))\n",
    "\n",
    "        if choose_randomly:\n",
    "            files = np.random.choice(filelist,size=numReviews,replace=False)\n",
    "        else:\n",
    "            files = [filelist[i]]\n",
    "\n",
    "        # forget the string expansion\n",
    "        # let\"s store them as a dict\n",
    "        allwordcounts = dict()\n",
    "        for file in files:\n",
    "            # ########################################\n",
    "            # # this makes the dicts if they're needed\n",
    "            # if isfile(file+\".dict\"):\n",
    "            #     my_dict = pickle.load( open( file+\".dict\", \"rb\" ) )\n",
    "            #     for word in my_dict:\n",
    "            #         if word in allwordcounts:\n",
    "            #             allwordcounts[word] += my_dict[word]\n",
    "            #         else:\n",
    "            #             allwordcounts[word] = my_dict[word]\n",
    "            # else:\n",
    "            #     # read the txt file\n",
    "            #     f = open(file+\".txt\",\"r\")\n",
    "            #     rawtext = f.read()\n",
    "            #     f.close()\n",
    "            #     # dictify_general it\n",
    "            #     tmp_dict = dict()\n",
    "            #     dictify_general(rawtext,tmp_dict)\n",
    "            #     pickle.dump( tmp_dict , open( file+\".dict\", \"wb\" ) )\n",
    "            #     # add to the full dict\n",
    "            #     dictify_general(rawtext,allwordcounts)\n",
    "\n",
    "            # ###################################################\n",
    "            # # this loads the dicts\n",
    "            # my_dict = pickle.load( open( file+\".dict\", \"rb\" ) )\n",
    "            # for word in my_dict:\n",
    "            #     if word in allwordcounts:\n",
    "            #         allwordcounts[word] += my_dict[word]\n",
    "            #     else:\n",
    "            #         allwordcounts[word] = my_dict[word]\n",
    "\n",
    "            ########################################\n",
    "            # this loads the files\n",
    "            f = open(file+\".txt\",\"r\")\n",
    "            rawtext = f.read()\n",
    "            f.close()\n",
    "            # add to the full dict\n",
    "            dictify_general(rawtext,allwordcounts)\n",
    "\n",
    "        for j in range(len(wordsRE)):\n",
    "            scores[j][i] = wordsRE[j].score(allwordcounts)\n",
    "\n",
    "    f = open(\"output/{0}-{1}-{2:.0f}-{3:.0f}.csv\".format(test,prefix,numReviews,numSamples),\"w\")\n",
    "    csv_writer = csv.writer(f)\n",
    "    for row in scores:\n",
    "        csv_writer.writerow(row)\n",
    "    f.close()\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading LabMT with stopVal=1.0, for 3731 words\n",
      "loading ANEW with stopVal=0.0, for 1034 words\n",
      "loading data/LIWC/LIWC2007_English100131_words.dic\n",
      "loading LIWC with stopVal=0.0, for 4483 words\n",
      "loading MPQA with stopVal=0.0, for 7192 words\n",
      "loading Liu with stopVal=0.0, for 6782 words\n",
      "loading WK with stopVal=0.0, for 13915 words\n",
      "loading PANAS-X with stopVal=0.0, for 20 words\n",
      "loading Pattern with stopVal=0.0, for 1528 words\n",
      "loading SentiWordNet with stopVal=0.0, for 147700 words\n",
      "loading AFINN with stopVal=0.0, for 2477 words\n",
      "oops, deal is both pos and negative\n",
      "oops, fine is both pos and negative\n",
      "oops, fine is both pos and negative\n",
      "oops, fun is both pos and negative\n",
      "oops, help is both pos and negative\n",
      "oops, laugh is both pos and negative\n",
      "oops, matter is both pos and negative\n",
      "oops, order is both pos and negative\n",
      "oops, particular is both pos and negative\n",
      "oops, pass is both pos and negative\n",
      "loading GI with stopVal=0.0, for 3629 words\n",
      "loading WDAL with stopVal=0.0, for 8743 words\n",
      "loading NRC with stopVal=0.0, for 1220176 words\n"
     ]
    }
   ],
   "source": [
    "stopVal = 0.0\n",
    "allDicts = (LabMT(stopVal=1.0),\n",
    "            ANEW(stopVal=stopVal),\n",
    "            LIWC(stopVal=stopVal),\n",
    "            MPQA(stopVal=stopVal),\n",
    "            Liu(stopVal=stopVal),\n",
    "            WK(stopVal=stopVal),\n",
    "            PANASX(stopVal=stopVal),\n",
    "            Pattern(stopVal=stopVal),\n",
    "            SentiWordNet(stopVal=stopVal),\n",
    "            AFINN(stopVal=stopVal),\n",
    "            GI(stopVal=stopVal),\n",
    "            WDAL(stopVal=stopVal),\n",
    "            NRC(stopVal=stopVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = [[[] for i in range(len(allLengths))],[[] for i in range(len(allLengths))]]\n",
    "for j,flip in enumerate([\"pos\",\"neg\"]):\n",
    "    files = [\"../data/moviereviews/txt_sentoken/{0}/{1}\".format(flip,x.replace(\".txt\",\"\"))\n",
    "             for x in listdir(\"../data/moviereviews/txt_sentoken/{0}/\".format(flip)) if \".txt\" in x]\n",
    "    prefix = \"{0}Scores\".format(flip)\n",
    "    for i,numReviews in enumerate(allLengths):\n",
    "        numSamples = allSamples[i]\n",
    "        print(\"taking {0} samples of {1} reviews\".format(numSamples,numReviews))\n",
    "        results[j][i] = sampleReviewsDict(numReviews,numSamples,files,allDicts,prefix,test=test_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negcolor = \"#4C4CFF\" # shift blue\n",
    "poscolor = \"#FFFF4C\" # shift yellow\n",
    "poscolor = \"#ff7f00\" # orange (shift yellow too hard to read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pos_scores = results[0]\n",
    "neg_scores = results[1]\n",
    "nbins=50\n",
    "review_length = 0\n",
    "dict_num = 0\n",
    "for dict_num,my_dict in enumerate(allDicts):\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_axes([0.15,0.2,0.7,0.7])\n",
    "    ax1.hist(pos_scores[review_length][dict_num], nbins, alpha=0.75, facecolor=\"#ef8a62\",)\n",
    "    ax1.hist(neg_scores[review_length][dict_num], nbins, alpha=0.75, facecolor=\"#2b8cbe\",)\n",
    "    ax1.legend([\"Positive reviews\",\"Negative reviews\"],loc=\"best\",framealpha=0.5)\n",
    "    # ax1.set_title(\"{0} score distribution for {1} reviews\".format(titles[j],allLengths[i]))\n",
    "    ax1.set_xlabel(\"Score\")\n",
    "    ax1.set_ylabel(\"Number of reviews\")\n",
    "    ax1.set_title(\"{} {}\".format(my_dict.title,my_dict.stopVal))\n",
    "\n",
    "    # mysavefig(\"{0}-{1}reviews-dist\".format(titles[j],allLengths[i]))\n",
    "    # mysavefig(\"{0}-{1}reviews-dist\".format(titles[j],allLengths[i]))\n",
    "    # mysavefig(\"reviews-dist-{0}-{1}.pdf\".format(titles[j],allLengths[i]),date=False,folder=\"figures/moviereviews\")\n",
    "    # plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flip = \"pos\"\n",
    "pos_files = [\"../data/moviereviews/txt_sentoken/{0}/{1}\".format(flip,x.replace(\".txt\",\"\"))\n",
    "             for x in listdir(\"../data/moviereviews/txt_sentoken/{0}/\".format(flip)) if \".txt\" in x]\n",
    "flip = \"neg\"\n",
    "neg_files = [\"../data/moviereviews/txt_sentoken/{0}/{1}\".format(flip,x.replace(\".txt\",\"\"))\n",
    "             for x in listdir(\"../data/moviereviews/txt_sentoken/{0}/\".format(flip)) if \".txt\" in x]\n",
    "pos_scores = sampleReviewsDict(1,1000,pos_files,[allDicts[0]],\"labMT-calibration-pos\",test=test_name)\n",
    "neg_scores = sampleReviewsDict(1,1000,neg_files,[allDicts[0]],\"labMT-calibration-neg\",test=test_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(pos_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(pos_scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pos_scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(neg_scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "average_score = np.mean(neg_scores[0]+pos_scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "j = 0\n",
    "# fraction of scores across the mean\n",
    "overlap = float(len(np.where(pos_scores[j] < average_score)[0]) + len(np.where(neg_scores[j] > average_score)[0])) /(len(pos_scores[j])+len(neg_scores[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allLabMT = [LabMT(stopVal=x) for x in np.arange(0,3.25,.25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_scores = sampleReviewsDict(1,1000,pos_files,allLabMT,\"labMT-calibration-pos\",test=\"\")\n",
    "neg_scores = sampleReviewsDict(1,1000,neg_files,allLabMT,\"labMT-calibration-neg\",test=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def overlap(p,n):\n",
    "    # pos scores and neg scores are lists of scores\n",
    "    # called p and n now\n",
    "    \n",
    "    # take the average\n",
    "    a = np.mean(n+p)\n",
    "    return float(len(np.where(p < a)[0]) + len(np.where(n > a)[0])) / (len(p+n))\n",
    "def overlap_center(p,n,a):\n",
    "    # pos scores and neg scores are lists of scores\n",
    "    # called p and n now\n",
    "    return float(len(np.where(p < a)[0]) + len(np.where(n > a)[0])) / (len(p+n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labMT_cal = [overlap(pos_scores[j],neg_scores[j]) for j in range(len(allLabMT))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labMT_cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_axes([0.15,0.2,0.7,0.7])\n",
    "ax1.plot(np.arange(0,3.25,.25),labMT_cal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calibrate(my_senti,my_range):\n",
    "    flip = \"pos\"\n",
    "    pos_files = [\"../data/moviereviews/txt_sentoken/{0}/{1}\".format(flip,x.replace(\".txt\",\"\"))\n",
    "                 for x in listdir(\"../data/moviereviews/txt_sentoken/{0}/\".format(flip)) if \".txt\" in x]\n",
    "    flip = \"neg\"\n",
    "    neg_files = [\"../data/moviereviews/txt_sentoken/{0}/{1}\".format(flip,x.replace(\".txt\",\"\"))\n",
    "                 for x in listdir(\"../data/moviereviews/txt_sentoken/{0}/\".format(flip)) if \".txt\" in x]\n",
    "    all_senti = [my_senti(stopVal=x) for x in my_range]\n",
    "    pos_scores = sampleReviewsDict(1,1000,pos_files,all_senti,\"{}-calibration-pos\".format(my_senti.title),test=\"\")\n",
    "    neg_scores = sampleReviewsDict(1,1000,neg_files,all_senti,\"{}-calibration-neg\".format(my_senti.title),test=\"\")\n",
    "    # greedy, just consider the overlap\n",
    "    my_cal_overlap = [overlap(pos_scores[j],neg_scores[j]) for j in range(len(all_senti))]    \n",
    "    # fix by the center of the scoring range\n",
    "    my_cal_center_fixed = [overlap(pos_scores[j],neg_scores[j],all_senti[0].center) for j in range(len(all_senti))]\n",
    "    # fix by the average of the words in that list\n",
    "    my_cal_center_avg = [overlap(pos_scores[j],neg_scores[j],np.mean(all_senti[j].scorelist)) for j in range(len(all_senti))]\n",
    "    my_cal_center_fixed_avg = [overlap(pos_scores[j],neg_scores[j],np.mean(all_senti[0].scorelist)) for j in range(len(all_senti))]\n",
    "    \n",
    "    print(\"overlap scores:\")\n",
    "    print(my_cal_overlap)\n",
    "    print(\"overlap of center scores:\")\n",
    "    print(my_cal_fixed)\n",
    "    print(\"overlap of avg floating scores:\")\n",
    "    print(my_cal_avg)\n",
    "    print(\"overlap of floating scores:\")\n",
    "    print(my_cal_avg)\n",
    "    \n",
    "#     fig = plt.figure()\n",
    "#     ax1 = fig.add_axes([0.15,0.2,0.7,0.7])\n",
    "#     ax1.plot(my_range,my_cal)\n",
    "#     ax1.set_title(\"{} Calibration\".format(my_senti.title))\n",
    "    return my_cal_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calibrate(LabMT,np.arange(0,3.25,.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calibrate(LabMT,np.arange(0,2.25,.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calibrate(LabMT,np.arange(0,2.5,.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calibrate(ANEW,np.arange(0,2.5,.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calibrate(LIWC,[0,.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calibrate(MPQA,[0,.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "calibrated_results = []\n",
    "calibrated_delh = []\n",
    "for my_senti_dict,cal_range in zip([LabMT,ANEW,WK,MPQA,LIWC,Liu,PANASX,pattern,sentiWordNet,AFINN,GI,WDAL,NRC],\n",
    "                                   [np.arange(0,2.5,.1),np.arange(0,2.5,.1),np.arange(0,2.5,.1),[0,0.5],[0,0.5],[0],\n",
    "                                    [0],np.arange(0,.7,.1),np.arange(0,1,.1),np.arange(.5,4.5,1.0),[0],np.arange(0,1,.1),\n",
    "                                    np.arange(0,3.5,.5)]):\n",
    "    a = calibrate(my_senti_dict,cal_range)\n",
    "    calibrated_results.append(np.min(a))\n",
    "    calibrated_delh.append(cal_range[np.where(a == np.min(a))[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_senti_dicts = [LabMT,ANEW,WK,MPQA,LIWC,Liu,PANASX,Pattern,SentiWordNet,AFINN,GI,WDAL,NRC]\n",
    "indexer = sorted(range(len(calibrated_results)),key=lambda i: calibrated_results[i])\n",
    "calibrated_results_sorted = [calibrated_results[i] for i in indexer]\n",
    "calibrated_delh_sorted = [calibrated_delh[i] for i in indexer]\n",
    "all_senti_dicts_sorted = [all_senti_dicts[i] for i in indexer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# f = open(\"all-reviews-table.tex\",\"w\")\n",
    "# f.write(r\"\"\"\\begin{tabular*}{ l | l | l | l }\n",
    "#     \\hline\n",
    "#     Rank & Dictionary & $\\Delta_h$ & Accuracy \\\\\n",
    "#     \\hline\n",
    "#     \\hline\n",
    "# \"\"\")\n",
    "# for i,c,n,h in zip(range(len(calibrated_results)),calibrated_results_sorted,all_senti_dicts_sorted,calibrated_delh_sorted):\n",
    "#     # print(\"{0:.1f} for {1} ({2:.2f})\".format((1-c)*100,n.title,h))\n",
    "#     # declare ties\n",
    "#     if i>0:\n",
    "#         if calibrated_results_sorted[i] == calibrated_results_sorted[i-1]:\n",
    "#             rank=i\n",
    "#         else:\n",
    "#             rank=i+1\n",
    "#     else:\n",
    "#         rank=1\n",
    "#     f.write(\"{0} & {1} & {2:.2f} & {3:.1f} \\\\\\\\ \\n\".format(rank,n.title,h,(1-c)*100))\n",
    "# f.write(\"\\end{tabular*}\")\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GI_pos_count = len([word for word in my_GI.data if my_GI.data[word][1] > 0])\n",
    "# GI_neg_count = len([word for word in my_GI.data if my_GI.data[word][1] < 0])\n",
    "# print(GI_pos_count)\n",
    "# print(GI_neg_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_movie_shifts(allDicts):\n",
    "    datastructure = \"marisatrie\"\n",
    "    stopVal = 0.0\n",
    "    flip = \"pos\"\n",
    "    pos_files = [\"../data/moviereviews/txt_sentoken/{0}/{1}\".format(flip,x.replace(\".txt\",\"\"))\n",
    "             for x in listdir(\"../data/moviereviews/txt_sentoken/{0}/\".format(flip)) if \".txt\" in x]\n",
    "    flip = \"neg\"\n",
    "    neg_files = [\"../data/moviereviews/txt_sentoken/{0}/{1}\".format(flip,x.replace(\".txt\",\"\"))\n",
    "             for x in listdir(\"../data/moviereviews/txt_sentoken/{0}/\".format(flip)) if \".txt\" in x]\n",
    "\n",
    "    neg_wordcounts = dict()\n",
    "    for file in neg_files:\n",
    "        # this loads the files\n",
    "        f = open(file+\".txt\",\"r\")\n",
    "        rawtext = f.read()\n",
    "        f.close()\n",
    "        # add to the full dict\n",
    "        dictify_general(rawtext,neg_wordcounts)\n",
    "\n",
    "    pos_wordcounts = dict()\n",
    "    for file in pos_files:\n",
    "        # this loads the files\n",
    "        f = open(file+\".txt\",\"r\")\n",
    "        rawtext = f.read()\n",
    "        f.close()\n",
    "        # add to the full dict\n",
    "        dictify_general(rawtext,pos_wordcounts)\n",
    "\n",
    "    for j,my_sentiDict in enumerate(allDicts):\n",
    "        pos_word_vec = my_sentiDict.wordVecify(pos_wordcounts)\n",
    "        neg_word_vec = my_sentiDict.wordVecify(neg_wordcounts)\n",
    "        for stopVal in [0.0,0.5,1.0,1.5,2.0,2.5]:\n",
    "            pos_word_vec_stopped = my_sentiDict.stopper(pos_word_vec,stopVal=stopVal)\n",
    "            neg_word_vec_stopped = my_sentiDict.stopper(neg_word_vec,stopVal=stopVal)\n",
    "            shiftHtml(my_sentiDict.scorelist, my_sentiDict.wordlist,\n",
    "                     neg_word_vec_stopped, pos_word_vec_stopped,\n",
    "                     \"../figures/moviereviews-shifts/movie-shift-{0:.0f}stop-{1}.html\".format(stopVal*10,my_sentiDict.title),\n",
    "                     # make_png_too=True,open_pdf=False,\n",
    "                     customTitle=True,\n",
    "                     title=\"{0}: {1} Wordshift\".format(letters[j],my_sentiDict.title),\n",
    "                     # title=\"Movie Review Wordshift using {0}\".format(my_sentiDict.corpus),\n",
    "                     ref_name=\"all negative reviews\",comp_name=\"all positive reviews\",)\n",
    "                     # ref_name_happs=\"All negative reviews\",comp_name_happs=\"All positive reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_senti_dicts_initialized = [all_senti_dicts[i](stopVal=0.0) for i in range(len(all_senti_dicts))]\n",
    "make_movie_shifts(all_senti_dicts_initialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_movie_shifts_optimal(allDicts,allStopVals,suffix):\n",
    "    datastructure = \"marisatrie\"\n",
    "    stopVal = 0.0\n",
    "    flip = \"pos\"\n",
    "    pos_files = [\"../data/moviereviews/txt_sentoken/{0}/{1}\".format(flip,x.replace(\".txt\",\"\"))\n",
    "             for x in listdir(\"../data/moviereviews/txt_sentoken/{0}/\".format(flip)) if \".txt\" in x]\n",
    "    flip = \"neg\"\n",
    "    neg_files = [\"../data/moviereviews/txt_sentoken/{0}/{1}\".format(flip,x.replace(\".txt\",\"\"))\n",
    "             for x in listdir(\"../data/moviereviews/txt_sentoken/{0}/\".format(flip)) if \".txt\" in x]\n",
    "\n",
    "    neg_wordcounts = dict()\n",
    "    for file in neg_files:\n",
    "        # this loads the files\n",
    "        f = open(file+\".txt\",\"r\")\n",
    "        rawtext = f.read()\n",
    "        f.close()\n",
    "        # add to the full dict\n",
    "        dictify_general(rawtext,neg_wordcounts)\n",
    "\n",
    "    pos_wordcounts = dict()\n",
    "    for file in pos_files:\n",
    "        # this loads the files\n",
    "        f = open(file+\".txt\",\"r\")\n",
    "        rawtext = f.read()\n",
    "        f.close()\n",
    "        # add to the full dict\n",
    "        dictify_general(rawtext,pos_wordcounts)\n",
    "\n",
    "    j = 0\n",
    "    for my_sentiDict,stopVal in zip(allDicts,allStopVals):\n",
    "        pos_word_vec = my_sentiDict.wordVecify(pos_wordcounts)\n",
    "        neg_word_vec = my_sentiDict.wordVecify(neg_wordcounts)\n",
    "        pos_word_vec_stopped = my_sentiDict.stopper(pos_word_vec,stopVal=stopVal)\n",
    "        neg_word_vec_stopped = my_sentiDict.stopper(neg_word_vec,stopVal=stopVal)\n",
    "        shiftHtml(my_sentiDict.scorelist, my_sentiDict.wordlist,\n",
    "                     neg_word_vec_stopped, pos_word_vec_stopped,\n",
    "                     \"../figures/moviereviews-shifts/movie-shift-calstop-{0}{1}.html\".format(my_sentiDict.folder,suffix),\n",
    "                     # make_png_too=True,open_pdf=False,\n",
    "                     customTitle=True,\n",
    "                     title=\"{0}: {1} Wordshift\".format(letters[j],my_sentiDict.folder),\n",
    "                     # title=\"Movie Review Wordshift using {0}\".format(my_sentiDict.corpus),\n",
    "                     ref_name=\"all negative reviews\",comp_name=\"all positive reviews\",)\n",
    "                     # ref_name_happs=\"All negative reviews\",comp_name_happs=\"All positive reviews\")\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_movie_shifts_optimal(all_senti_dicts_initialized,calibrated_delh,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make_movie_shifts_optimal(all_senti_dicts_initialized[6:],calibrated_delh[6:],\"-no-offset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
