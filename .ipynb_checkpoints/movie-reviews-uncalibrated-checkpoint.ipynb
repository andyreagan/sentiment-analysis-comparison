{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncalibrated test of binary classification of movie reviews.\n",
    "\n",
    "Perviously, we calibrated the results before using a training set, tuning the decision boundary and \\Delta h for the most accuracy on that training set.\n",
    "\n",
    "This is reasonable, and of course will result in a overall increase in performance across all dictionaries if the movie reviews (even the positive ones) are more \"negative\". And tuning \\Delta h is reasonable too. \n",
    "\n",
    "Here, we won't tune the results and just choose the decision boundary as the average of word scores, or the center for the dictionary, whichever is better (because the method of construction would tell you which makes sense).\n",
    "\n",
    "Also, more dictionaries added, and we'll consider the performace for evaluation of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/andyreagan/tools/python/labMTsimple/\")\n",
    "from labMTsimple.speedy import *\n",
    "from labMTsimple.storyLab import *\n",
    "\n",
    "import re\n",
    "import codecs\n",
    "from os import listdir,mkdir\n",
    "from os.path import isfile,isdir\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import rc,rcParams\n",
    "rc(\"xtick\", labelsize=8)\n",
    "rc(\"ytick\", labelsize=8)\n",
    "rc(\"font\",**{\"family\":\"serif\",\"serif\":[\"cmr10\"]})\n",
    "# rc(\"text\", usetex=True)\n",
    "figwidth_onecol = 8.5\n",
    "figwidth_twocol = figwidth_onecol/2\n",
    "\n",
    "import numpy as np\n",
    "from json import loads\n",
    "import csv\n",
    "from datetime import datetime,timedelta\n",
    "import pickle\n",
    "\n",
    "from subprocess import call\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "error_logging = True\n",
    "sys.path.append(\"/Users/andyreagan/tools/python/kitchentable\")\n",
    "from dogtoys import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sampleReviewsDict(numReviews,numSamples,filelist,wordsRE,test=\"\",prefix=\"\"):\n",
    "    \"\"\"Sample from all of the review.\"\"\"\n",
    "    if numReviews == 1:\n",
    "        choose_randomly = False\n",
    "    else:\n",
    "        choose_randomly = True\n",
    "\n",
    "    scores = [[0.0 for i in range(numSamples)] for j in range(len(wordsRE))]\n",
    "    for i in range(numSamples):\n",
    "        # print(\"on sample {0}\".format(i))\n",
    "\n",
    "        if choose_randomly:\n",
    "            files = np.random.choice(filelist,size=numReviews,replace=False)\n",
    "        else:\n",
    "            files = [filelist[i]]\n",
    "\n",
    "        # forget the string expansion\n",
    "        # let\"s store them as a dict\n",
    "        allwordcounts = dict()\n",
    "        for file in files:\n",
    "            # ########################################\n",
    "            # # this makes the dicts if they're needed\n",
    "            # if isfile(file+\".dict\"):\n",
    "            #     my_dict = pickle.load( open( file+\".dict\", \"rb\" ) )\n",
    "            #     for word in my_dict:\n",
    "            #         if word in allwordcounts:\n",
    "            #             allwordcounts[word] += my_dict[word]\n",
    "            #         else:\n",
    "            #             allwordcounts[word] = my_dict[word]\n",
    "            # else:\n",
    "            #     # read the txt file\n",
    "            #     f = open(file+\".txt\",\"r\")\n",
    "            #     rawtext = f.read()\n",
    "            #     f.close()\n",
    "            #     # dictify_general it\n",
    "            #     tmp_dict = dict()\n",
    "            #     dictify_general(rawtext,tmp_dict)\n",
    "            #     pickle.dump( tmp_dict , open( file+\".dict\", \"wb\" ) )\n",
    "            #     # add to the full dict\n",
    "            #     dictify_general(rawtext,allwordcounts)\n",
    "\n",
    "            # ###################################################\n",
    "            # # this loads the dicts\n",
    "            # my_dict = pickle.load( open( file+\".dict\", \"rb\" ) )\n",
    "            # for word in my_dict:\n",
    "            #     if word in allwordcounts:\n",
    "            #         allwordcounts[word] += my_dict[word]\n",
    "            #     else:\n",
    "            #         allwordcounts[word] = my_dict[word]\n",
    "\n",
    "            ########################################\n",
    "            # this loads the files\n",
    "            f = open(file+\".txt\",\"r\")\n",
    "            rawtext = f.read()\n",
    "            f.close()\n",
    "            # add to the full dict\n",
    "            dictify_general(rawtext,allwordcounts)\n",
    "\n",
    "        for j in range(len(wordsRE)):\n",
    "            scores[j][i] = wordsRE[j].score(allwordcounts,center=1000.0)\n",
    "    \n",
    "    if len(test) > 0:\n",
    "        f = open(\"output/{0}-{1}-{2:.0f}-{3:.0f}.csv\".format(test,prefix,numReviews,numSamples),\"w\")\n",
    "        csv_writer = csv.writer(f)\n",
    "        for row in scores:\n",
    "            csv_writer.writerow(row)\n",
    "        f.close()\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifier_perf(conf_mat,v=True):\n",
    "    \"\"\"Given the confusion matrix, produce precision, recall, and f1-score.\n",
    "    Actual going down, predicited going across.\"\"\"\n",
    "    \n",
    "    N = conf_mat.shape[0]\n",
    "    # could do these computations using matrix math...\n",
    "    R = np.array([conf_mat[i,i]/conf_mat[i,:].sum() for i in range(N)])\n",
    "    P = np.array([conf_mat[i,i]/conf_mat[:,i].sum() for i in range(N)])\n",
    "\n",
    "    F1 = np.array([2*R[i]*P[i]/(R[i]+P[i]) for i in range(N)])\n",
    "    if v:\n",
    "        print(R)\n",
    "        print(P)\n",
    "        print(F1)\n",
    "    return F1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flip = \"pos\"\n",
    "pos_files = [\"../data/moviereviews/txt_sentoken/{0}/{1}\".format(flip,x.replace(\".txt\",\"\"))\n",
    "             for x in listdir(\"../data/moviereviews/txt_sentoken/{0}/\".format(flip)) if \".txt\" in x]\n",
    "flip = \"neg\"\n",
    "neg_files = [\"../data/moviereviews/txt_sentoken/{0}/{1}\".format(flip,x.replace(\".txt\",\"\"))\n",
    "             for x in listdir(\"../data/moviereviews/txt_sentoken/{0}/\".format(flip)) if \".txt\" in x]\n",
    "all_senti_dicts = [LabMT(),ANEW(),WK(),MPQA(),\n",
    "                   LIWC01(),LIWC07(),LIWC15(),\n",
    "                   OL(),PANASX(),Pattern(),\n",
    "                   SentiWordNet(),AFINN(),GI(),\n",
    "                   WDAL(),Sent140Lex(),MaxDiff(),\n",
    "                   HashtagSent(),EmoLex(),\n",
    "                   SOCAL(),SenticNet(),\n",
    "                   Emoticons(),SentiStrength(),VADER(),\n",
    "                   Umigon(),USent(),EmoSenticNet()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_scores = sampleReviewsDict(1,1000,pos_files,all_senti_dicts)\n",
    "neg_scores = sampleReviewsDict(1,1000,neg_files,all_senti_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 739.  261.]\n",
      " [ 471.  529.]]\n",
      "[ 0.739  0.529]\n",
      "[ 0.6107438   0.66962025]\n",
      "[ 0.66877828  0.59106145]\n",
      "[[ 1000.     0.]\n",
      " [ 1000.     0.]]\n",
      "[ 1.  0.]\n",
      "[ 0.5  nan]\n",
      "[ 0.66666667         nan]\n",
      "[[ 595.  307.]\n",
      " [ 347.  556.]]\n",
      "[ 0.65964523  0.61572536]\n",
      "[ 0.63163482  0.64426419]\n",
      "[ 0.64533623  0.62967157]\n",
      "[        nan  0.62991987  0.        ]\n",
      "[ 0.62991987  0.        ]\n",
      "labMT 0.629919866528 nan 0.637503899888 100.0\n",
      "[[ 955.   45.]\n",
      " [ 962.   38.]]\n",
      "[ 0.955  0.038]\n",
      "[ 0.49817423  0.45783133]\n",
      "[ 0.65478231  0.07017544]\n",
      "[[ 974.   26.]\n",
      " [ 975.   25.]]\n",
      "[ 0.974  0.025]\n",
      "[ 0.49974346  0.49019608]\n",
      "[ 0.6605629   0.04757374]\n",
      "[[ 551.  358.]\n",
      " [ 425.  481.]]\n",
      "[ 0.60616062  0.53090508]\n",
      "[ 0.56454918  0.57330155]\n",
      "[ 0.58461538  0.5512894 ]\n",
      "[ 0.35406832  0.36247887  0.        ]\n",
      "[ 0.35406832  0.36247887  0.        ]\n",
      "ANEW 0.362478874595 0.354068320987 0.567952391448 100.0\n",
      "[[ 1000.     0.]\n",
      " [  998.     2.]]\n",
      "[ 1.     0.002]\n",
      "[ 0.5005005  1.       ]\n",
      "[ 0.66711141  0.00399202]\n",
      "[[ 1000.     0.]\n",
      " [  999.     1.]]\n",
      "[ 1.     0.001]\n",
      "[ 0.50025013  1.        ]\n",
      "[ 0.66688896  0.001998  ]\n",
      "[[ 501.  404.]\n",
      " [ 269.  638.]]\n",
      "[ 0.55359116  0.70341786]\n",
      "[ 0.65064935  0.61228407]\n",
      "[ 0.59820896  0.65469472]\n",
      "[ 0.33444348  0.33555171  0.        ]\n",
      "[ 0.33444348  0.33555171  0.        ]\n",
      "WK 0.335551711787 0.334443482493 0.626451835231 100.0\n",
      "[[ 997.    3.]\n",
      " [ 972.   28.]]\n",
      "[ 0.997  0.028]\n",
      "[ 0.5063484   0.90322581]\n",
      "[ 0.6716066  0.0543162]\n",
      "[[ 712.  262.]\n",
      " [ 399.  571.]]\n",
      "[ 0.73100616  0.58865979]\n",
      "[ 0.64086409  0.68547419]\n",
      "[ 0.68297362  0.6333888 ]\n",
      "[[ 581.  322.]\n",
      " [ 283.  623.]]\n",
      "[ 0.64341085  0.68763797]\n",
      "[ 0.6724537   0.65925926]\n",
      "[ 0.65761177  0.67314965]\n",
      "[ 0.65818121  0.3629614   0.        ]\n",
      "[ 0.65818121  0.3629614   0.        ]\n",
      "MPQA 0.362961399708 0.658181208777 0.665380710101 100.0\n",
      "[[ 995.    5.]\n",
      " [ 980.   20.]]\n",
      "[ 0.995  0.02 ]\n",
      "[ 0.50379747  0.8       ]\n",
      "[ 0.66890756  0.03902439]\n",
      "[[ 855.  118.]\n",
      " [ 681.  275.]]\n",
      "[ 0.87872559  0.2876569 ]\n",
      "[ 0.55664062  0.69974555]\n",
      "[ 0.68154643  0.40770941]\n",
      "[[ 550.  354.]\n",
      " [ 285.  617.]]\n",
      "[ 0.60840708  0.68403548]\n",
      "[ 0.65868263  0.63542739]\n",
      "[ 0.63254744  0.65883609]\n",
      "[ 0.54462792  0.35396598  0.        ]\n",
      "[ 0.54462792  0.35396598  0.        ]\n",
      "LIWC01 0.353965976635 0.544627923611 0.645691766445 100.0\n",
      "[[ 981.   19.]\n",
      " [ 948.   52.]]\n",
      "[ 0.981  0.052]\n",
      "[ 0.50855365  0.73239437]\n",
      "[ 0.66985319  0.09710551]\n",
      "[[ 864.  112.]\n",
      " [ 698.  252.]]\n",
      "[ 0.8852459   0.26526316]\n",
      "[ 0.553137    0.69230769]\n",
      "[ 0.68085106  0.38356164]\n",
      "[[ 542.  362.]\n",
      " [ 288.  618.]]\n",
      "[ 0.59955752  0.68211921]\n",
      "[ 0.65301205  0.63061224]\n",
      "[ 0.62514418  0.65535525]\n",
      "[ 0.53220635  0.38347935  0.        ]\n",
      "[ 0.53220635  0.38347935  0.        ]\n",
      "LIWC07 0.383479350543 0.532206353833 0.640249712261 100.0\n",
      "[[ 963.   37.]\n",
      " [ 896.  104.]]\n",
      "[ 0.963  0.104]\n",
      "[ 0.51802044  0.73758865]\n",
      "[ 0.67366212  0.18229623]\n",
      "[[ 852.  126.]\n",
      " [ 664.  282.]]\n",
      "[ 0.87116564  0.29809725]\n",
      "[ 0.56200528  0.69117647]\n",
      "[ 0.68323978  0.41654357]\n",
      "[[ 509.  393.]\n",
      " [ 260.  646.]]\n",
      "[ 0.56430155  0.71302428]\n",
      "[ 0.66189857  0.62175168]\n",
      "[ 0.60921604  0.66426735]\n",
      "[ 0.54989168  0.42797918  0.        ]\n",
      "[ 0.54989168  0.42797918  0.        ]\n",
      "LIWC15 0.427979175499 0.549891675027 0.636741695243 100.0\n",
      "[[ 989.   11.]\n",
      " [ 922.   78.]]\n",
      "[ 0.989  0.078]\n",
      "[ 0.51753009  0.87640449]\n",
      "[ 0.67949158  0.14325069]\n",
      "[[ 646.  320.]\n",
      " [ 251.  722.]]\n",
      "[ 0.66873706  0.74203494]\n",
      "[ 0.72017837  0.69289827]\n",
      "[ 0.6935051   0.71662531]\n",
      "[[ 645.  262.]\n",
      " [ 281.  621.]]\n",
      "[ 0.71113561  0.68847007]\n",
      "[ 0.69654428  0.70328426]\n",
      "[ 0.70376432  0.69579832]\n",
      "[ 0.7050652   0.41137114  0.        ]\n",
      "[ 0.7050652   0.41137114  0.        ]\n",
      "OL 0.411371136177 0.705065204738 0.699781320057 100.0\n",
      "[[ 273.   92.]\n",
      " [ 202.   87.]]\n",
      "[ 0.74794521  0.30103806]\n",
      "[ 0.57473684  0.48603352]\n",
      "[ 0.65        0.37179487]\n",
      "[[ 273.   92.]\n",
      " [ 202.   87.]]\n",
      "[ 0.74794521  0.30103806]\n",
      "[ 0.57473684  0.48603352]\n",
      "[ 0.65        0.37179487]\n",
      "[[ 229.  109.]\n",
      " [ 181.  101.]]\n",
      "[ 0.67751479  0.35815603]\n",
      "[ 0.55853659  0.48095238]\n",
      "[ 0.61229947  0.41056911]\n",
      "[ 0.51089744  0.51089744  0.        ]\n",
      "[ 0.51089744  0.51089744  0.        ]\n",
      "PANAS-X 0.510897435897 0.510897435897 0.511434285466 32.7\n",
      "[[ 978.   22.]\n",
      " [ 837.  163.]]\n",
      "[ 0.978  0.163]\n",
      "[ 0.53884298  0.88108108]\n",
      "[ 0.69484902  0.27510549]\n",
      "[[ 969.   31.]\n",
      " [ 786.  214.]]\n",
      "[ 0.969  0.214]\n",
      "[ 0.55213675  0.87346939]\n",
      "[ 0.70344828  0.3437751 ]\n",
      "[[ 707.  198.]\n",
      " [ 289.  617.]]\n",
      "[ 0.78121547  0.68101545]\n",
      "[ 0.70983936  0.75705521]\n",
      "[ 0.74381904  0.71702499]\n",
      "[ 0.52361169  0.48497725  0.        ]\n",
      "[ 0.52361169  0.48497725  0.        ]\n",
      "Pattern 0.484977254161 0.523611688132 0.730422014041 100.0\n",
      "[[ 941.   59.]\n",
      " [ 804.  196.]]\n",
      "[ 0.941  0.196]\n",
      "[ 0.53925501  0.76862745]\n",
      "[ 0.6856102  0.3123506]\n",
      "[[ 711.  289.]\n",
      " [ 408.  592.]]\n",
      "[ 0.711  0.592]\n",
      "[ 0.63538874  0.67196368]\n",
      "[ 0.67107126  0.62945242]\n",
      "[[ 530.  374.]\n",
      " [ 256.  652.]]\n",
      "[ 0.58628319  0.71806167]\n",
      "[ 0.67430025  0.63547758]\n",
      "[ 0.62721893  0.67425026]\n",
      "[ 0.65026184  0.4989804   0.        ]\n",
      "[ 0.65026184  0.4989804   0.        ]\n",
      "SentiWordNet 0.498980398987 0.650261839477 0.650734596721 100.0\n",
      "[[ 970.   30.]\n",
      " [ 896.  104.]]\n",
      "[ 0.97   0.104]\n",
      "[ 0.51982851  0.7761194 ]\n",
      "[ 0.67690161  0.18342152]\n",
      "[[ 798.  196.]\n",
      " [ 525.  463.]]\n",
      "[ 0.8028169   0.46862348]\n",
      "[ 0.6031746   0.70257967]\n",
      "[ 0.68882175  0.56223437]\n",
      "[[ 619.  289.]\n",
      " [ 312.  589.]]\n",
      "[ 0.68171806  0.65371809]\n",
      "[ 0.66487648  0.67084282]\n",
      "[ 0.67319195  0.66216976]\n",
      "[ 0.62552806  0.43016156  0.        ]\n",
      "[ 0.62552806  0.43016156  0.        ]\n",
      "AFINN 0.43016156089 0.625528058889 0.66768085522 100.0\n",
      "[[ 924.   76.]\n",
      " [ 768.  232.]]\n",
      "[ 0.924  0.232]\n",
      "[ 0.54609929  0.75324675]\n",
      "[ 0.68647845  0.35474006]\n",
      "[[ 799.  188.]\n",
      " [ 554.  415.]]\n",
      "[ 0.80952381  0.42827657]\n",
      "[ 0.59053954  0.68822554]\n",
      "[ 0.68290598  0.52798982]\n",
      "[[ 546.  360.]\n",
      " [ 266.  635.]]\n",
      "[ 0.60264901  0.70477248]\n",
      "[ 0.67241379  0.63819095]\n",
      "[ 0.63562282  0.66983122]\n",
      "[ 0.6054479   0.52060926  0.        ]\n",
      "[ 0.6054479   0.52060926  0.        ]\n",
      "GI 0.520609257921 0.605447902394 0.652727020429 100.0\n",
      "[[ 665.  335.]\n",
      " [ 480.  520.]]\n",
      "[ 0.665  0.52 ]\n",
      "[ 0.58078603  0.60818713]\n",
      "[ 0.62004662  0.5606469 ]\n",
      "[[ 1000.     0.]\n",
      " [ 1000.     0.]]\n",
      "[ 1.  0.]\n",
      "[ 0.5  nan]\n",
      "[ 0.66666667         nan]\n",
      "[[ 562.  340.]\n",
      " [ 380.  524.]]\n",
      "[ 0.62305987  0.57964602]\n",
      "[ 0.59660297  0.60648148]\n",
      "[ 0.60954447  0.59276018]\n",
      "[        nan  0.59034676  0.        ]\n",
      "[ 0.59034676  0.        ]\n",
      "WDAL 0.590346760158 nan 0.601152324771 100.0\n",
      "[[    0.  1000.]\n",
      " [    0.  1000.]]\n",
      "[ 0.  1.]\n",
      "[ nan  0.5]\n",
      "[        nan  0.66666667]\n",
      "[[ 966.   34.]\n",
      " [ 854.  146.]]\n",
      "[ 0.966  0.146]\n",
      "[ 0.53076923  0.81111111]\n",
      "[ 0.68510638  0.24745763]\n",
      "[[ 600.  302.]\n",
      " [ 275.  629.]]\n",
      "[ 0.66518847  0.69579646]\n",
      "[ 0.68571429  0.67561762]\n",
      "[ 0.67529544  0.68555858]\n",
      "[ 0.46628201         nan  0.        ]\n",
      "[ 0.46628201  0.        ]\n",
      "Sent140Lex nan 0.466282005049 0.680427012431 100.0\n",
      "[[ 996.    4.]\n",
      " [ 979.   21.]]\n",
      "[ 0.996  0.021]\n",
      "[ 0.5043038  0.84     ]\n",
      "[ 0.66957983  0.04097561]\n",
      "[[ 996.    4.]\n",
      " [ 979.   21.]]\n",
      "[ 0.996  0.021]\n",
      "[ 0.5043038  0.84     ]\n",
      "[ 0.66957983  0.04097561]\n",
      "[[ 571.  332.]\n",
      " [ 284.  621.]]\n",
      "[ 0.63233666  0.68618785]\n",
      "[ 0.66783626  0.65162644]\n",
      "[ 0.64960182  0.66846071]\n",
      "[ 0.35527772  0.35527772  0.        ]\n",
      "[ 0.35527772  0.35527772  0.        ]\n",
      "MaxDiff 0.355277720844 0.355277720844 0.659031265346 100.0\n",
      "[[ 194.  806.]\n",
      " [  48.  952.]]\n",
      "[ 0.194  0.952]\n",
      "[ 0.80165289  0.54152446]\n",
      "[ 0.31239936  0.69035533]\n",
      "[[ 666.  334.]\n",
      " [ 338.  662.]]\n",
      "[ 0.666  0.662]\n",
      "[ 0.66334661  0.66465863]\n",
      "[ 0.66467066  0.66332665]\n",
      "[[ 595.  310.]\n",
      " [ 296.  611.]]\n",
      "[ 0.65745856  0.67364939]\n",
      "[ 0.667789    0.66340934]\n",
      "[ 0.66258352  0.66849015]\n",
      "[ 0.66399866  0.50137734  0.        ]\n",
      "[ 0.66399866  0.50137734  0.        ]\n",
      "HashtagSent 0.501377342913 0.663998655995 0.665536836052 100.0\n",
      "[[ 976.   24.]\n",
      " [ 922.   78.]]\n",
      "[ 0.976  0.078]\n",
      "[ 0.5142255   0.76470588]\n",
      "[ 0.67356798  0.1415608 ]\n",
      "[[ 885.   97.]\n",
      " [ 676.  285.]]\n",
      "[ 0.901222    0.29656608]\n",
      "[ 0.56694427  0.7460733 ]\n",
      "[ 0.69602831  0.42442293]\n",
      "[[ 569.  339.]\n",
      " [ 288.  616.]]\n",
      "[ 0.62665198  0.68141593]\n",
      "[ 0.66394399  0.64502618]\n",
      "[ 0.64475921  0.66272189]\n",
      "[ 0.56022562  0.40756439  0.        ]\n",
      "[ 0.56022562  0.40756439  0.        ]\n",
      "EmoLex 0.407564388232 0.560225623373 0.653740550145 100.0\n",
      "[[ 970.   30.]\n",
      " [ 794.  206.]]\n",
      "[ 0.97   0.206]\n",
      "[ 0.54988662  0.87288136]\n",
      "[ 0.70188133  0.33333333]\n",
      "[[ 939.   61.]\n",
      " [ 664.  336.]]\n",
      "[ 0.939  0.336]\n",
      "[ 0.58577667  0.84634761]\n",
      "[ 0.72147522  0.48103078]\n",
      "[[ 635.  268.]\n",
      " [ 248.  657.]]\n",
      "[ 0.70321152  0.72596685]\n",
      "[ 0.7191393   0.71027027]\n",
      "[ 0.71108623  0.71803279]\n",
      "[ 0.601253    0.51760733  0.        ]\n",
      "[ 0.601253    0.51760733  0.        ]\n",
      "SOCAL 0.517607332369 0.601253000571 0.714559506545 100.0\n",
      "[[ 989.   11.]\n",
      " [ 958.   42.]]\n",
      "[ 0.989  0.042]\n",
      "[ 0.50796097  0.79245283]\n",
      "[ 0.67119104  0.07977208]\n",
      "[[ 945.   55.]\n",
      " [ 867.  133.]]\n",
      "[ 0.945  0.133]\n",
      "[ 0.52152318  0.70744681]\n",
      "[ 0.67211949  0.22390572]\n",
      "[[ 530.  379.]\n",
      " [ 312.  594.]]\n",
      "[ 0.58305831  0.65562914]\n",
      "[ 0.62945368  0.61048304]\n",
      "[ 0.60536836  0.6322512 ]\n",
      "[ 0.44801261  0.37548156  0.        ]\n",
      "[ 0.44801261  0.37548156  0.        ]\n",
      "SenticNet 0.375481560755 0.448012605907 0.618809779191 100.0\n",
      "[[ 0.  0.]\n",
      " [ 1.  0.]]\n",
      "[ nan   0.]\n",
      "[  0.  nan]\n",
      "[ nan  nan]\n",
      "[[ 0.  0.]\n",
      " [ 1.  0.]]\n",
      "[ nan   0.]\n",
      "[  0.  nan]\n",
      "[ nan  nan]\n",
      "[[ 0.  0.]\n",
      " [ 0.  0.]]\n",
      "[ nan  nan]\n",
      "[ nan  nan]\n",
      "[ nan  nan]\n",
      "[ nan  nan   0.]\n",
      "[ 0.]\n",
      "Emoticons nan nan nan 0.05\n",
      "[[ 969.   31.]\n",
      " [ 942.   58.]]\n",
      "[ 0.969  0.058]\n",
      "[ 0.50706436  0.65168539]\n",
      "[ 0.6657506   0.10651974]\n",
      "[[ 358.  636.]\n",
      " [ 145.  842.]]\n",
      "[ 0.36016097  0.85309017]\n",
      "[ 0.71172962  0.56968877]\n",
      "[ 0.47828991  0.6831643 ]\n",
      "[[ 543.  361.]\n",
      " [ 308.  602.]]\n",
      "[ 0.60066372  0.66153846]\n",
      "[ 0.63807286  0.6251298 ]\n",
      "[ 0.61880342  0.64281901]\n",
      "[ 0.58072711  0.38613517  0.        ]\n",
      "[ 0.58072711  0.38613517  0.        ]\n",
      "SentiStrength 0.386135172026 0.580727106681 0.630811212872 100.0\n",
      "[[ 906.   94.]\n",
      " [ 765.  235.]]\n",
      "[ 0.906  0.235]\n",
      "[ 0.54219031  0.71428571]\n",
      "[ 0.6783976   0.35364936]\n",
      "[[ 832.  168.]\n",
      " [ 596.  404.]]\n",
      "[ 0.832  0.404]\n",
      "[ 0.58263305  0.70629371]\n",
      "[ 0.68533773  0.51399491]\n",
      "[[ 619.  287.]\n",
      " [ 305.  598.]]\n",
      "[ 0.68322296  0.66223699]\n",
      "[ 0.66991342  0.67570621]\n",
      "[ 0.67650273  0.6689038 ]\n",
      "[ 0.59966632  0.51602348  0.        ]\n",
      "[ 0.59966632  0.51602348  0.        ]\n",
      "VADER 0.516023482158 0.599666318733 0.672703267686 100.0\n",
      "[[ 833.  167.]\n",
      " [ 563.  437.]]\n",
      "[ 0.833  0.437]\n",
      "[ 0.59670487  0.72350993]\n",
      "[ 0.69532554  0.54488778]\n",
      "[[ 412.  521.]\n",
      " [ 165.  791.]]\n",
      "[ 0.44158628  0.82740586]\n",
      "[ 0.71403813  0.60289634]\n",
      "[ 0.54569536  0.69753086]\n",
      "[[ 563.  342.]\n",
      " [ 291.  613.]]\n",
      "[ 0.62209945  0.67809735]\n",
      "[ 0.65925059  0.64188482]\n",
      "[ 0.64013644  0.65949435]\n",
      "[ 0.62161311  0.62010666  0.        ]\n",
      "[ 0.62161311  0.62010666  0.        ]\n",
      "Umigon 0.62010666156 0.621613114218 0.649815396481 100.0\n",
      "[[   0.  363.]\n",
      " [   0.  440.]]\n",
      "[ 0.  1.]\n",
      "[        nan  0.54794521]\n",
      "[       nan  0.7079646]\n",
      "[[   0.  363.]\n",
      " [   0.  440.]]\n",
      "[ 0.  1.]\n",
      "[        nan  0.54794521]\n",
      "[       nan  0.7079646]\n",
      "[[ 0.  0.]\n",
      " [ 0.  0.]]\n",
      "[ nan  nan]\n",
      "[ nan  nan]\n",
      "[ nan  nan]\n",
      "[ nan  nan   0.]\n",
      "[ 0.]\n",
      "USent nan nan nan 40.15\n",
      "[[ 1000.     0.]\n",
      " [  995.     5.]]\n",
      "[ 1.     0.005]\n",
      "[ 0.50125313  1.        ]\n",
      "[ 0.66777963  0.00995025]\n",
      "[[ 1000.     0.]\n",
      " [ 1000.     0.]]\n",
      "[ 1.  0.]\n",
      "[ 0.5  nan]\n",
      "[ 0.66666667         nan]\n",
      "[[ 528.  376.]\n",
      " [ 384.  518.]]\n",
      "[ 0.5840708   0.57427938]\n",
      "[ 0.57894737  0.57941834]\n",
      "[ 0.5814978   0.57683742]\n",
      "[        nan  0.33886494  0.        ]\n",
      "[ 0.33886494  0.        ]\n",
      "EmoSenticNet 0.338864940739 nan 0.579167606919 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py:37: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py:42: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py:7: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/usr/local/lib/python3.5/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n",
      "/usr/local/lib/python3.5/site-packages/numpy/core/_methods.py:70: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py:47: RuntimeWarning: invalid value encountered in greater\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py:48: RuntimeWarning: invalid value encountered in less\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py:49: RuntimeWarning: invalid value encountered in greater\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py:50: RuntimeWarning: invalid value encountered in less\n"
     ]
    }
   ],
   "source": [
    "# conf_mats = [np.zeros((2,2)) for x in all_senti_dicts]\n",
    "F1_scores_mean = np.zeros(len(all_senti_dicts))\n",
    "F1_scores_center = np.zeros(len(all_senti_dicts))\n",
    "F1_scores_trained = np.zeros(len(all_senti_dicts))\n",
    "perc_scored = np.zeros(len(all_senti_dicts))\n",
    "all_data = []\n",
    "for i,x in enumerate(all_senti_dicts):\n",
    "    data = [x.title]\n",
    "    conf_mat = np.zeros((2,2))\n",
    "    a = np.array(pos_scores[i])\n",
    "    # print(len(a[a==1000.0]),len(a[a!=1000.0]),len(a[(a!=1000.0) & (a>x.scorelist.mean())]))\n",
    "    conf_mat[0,0] = len(a[(a!=1000.0) & (a>x.scorelist.mean())])\n",
    "    conf_mat[0,1] = len(a[(a!=1000.0) & (a<x.scorelist.mean())])\n",
    "    a = np.array(neg_scores[i])\n",
    "    conf_mat[1,0] = len(a[(a!=1000.0) & (a>x.scorelist.mean())])\n",
    "    conf_mat[1,1] = len(a[(a!=1000.0) & (a<x.scorelist.mean())])\n",
    "    print(conf_mat)\n",
    "    F1_scores_mean[i] = classifier_perf(conf_mat)\n",
    "    perc_scored[i] = 100*conf_mat.sum()/(len(pos_scores[i])+len(neg_scores[i]))\n",
    "    data.append(perc_scored[i])\n",
    "    data.append(conf_mat)\n",
    "    data.append(F1_scores_mean[i])\n",
    "    conf_mat = np.zeros((2,2))\n",
    "    a = np.array(pos_scores[i])\n",
    "    conf_mat[0,0] = len(a[(a!=1000.0) & (a>x.center)])\n",
    "    conf_mat[0,1] = len(a[(a!=1000.0) & (a<x.center)])\n",
    "    a = np.array(neg_scores[i])\n",
    "    conf_mat[1,0] = len(a[(a!=1000.0) & (a>x.center)])\n",
    "    conf_mat[1,1] = len(a[(a!=1000.0) & (a<x.center)])\n",
    "    print(conf_mat)\n",
    "    F1_scores_center[i] = classifier_perf(conf_mat)\n",
    "    data.append(conf_mat)\n",
    "    data.append(F1_scores_center[i])\n",
    "    total_n_samples = len(pos_scores[i])+len(neg_scores[i])\n",
    "    # grab 100 pos reviews\n",
    "    a = np.array(pos_scores[i])\n",
    "    r = np.random.choice(np.arange(len(pos_scores[i])),size=.05*total_n_samples)\n",
    "    b = np.zeros(len(pos_scores[i]))\n",
    "    b[r] = 1\n",
    "    # grab 100 neg reviews\n",
    "    a_ = np.array(neg_scores[i])\n",
    "    r_ = np.random.choice(np.arange(len(neg_scores[i])),size=.05*total_n_samples)\n",
    "    b_ = np.zeros(len(neg_scores[i]))\n",
    "    b_[r_] = 1\n",
    "    avg = np.concatenate((a[(a!=1000.0) & (b>0)],a_[(a_!=1000.0) & (b_>0)])).mean()\n",
    "    conf_mat = np.zeros((2,2))\n",
    "    conf_mat[0,0] = len(a[(a!=1000.0) & (a>avg) & (b<1)])\n",
    "    conf_mat[0,1] = len(a[(a!=1000.0) & (a<avg) & (b<1)])\n",
    "    conf_mat[1,0] = len(a_[(a_!=1000.0) & (a_>avg) & (b_<1)])\n",
    "    conf_mat[1,1] = len(a_[(a_!=1000.0) & (a_<avg) & (b_<1)])\n",
    "    print(conf_mat)\n",
    "    F1_scores_trained[i] = classifier_perf(conf_mat)\n",
    "    data.append(conf_mat)\n",
    "    data.append(F1_scores_trained[i])\n",
    "    untrained = np.array([F1_scores_center[i],F1_scores_mean[i],0.0])\n",
    "    print(untrained)\n",
    "    print(untrained[~np.isnan(untrained)])\n",
    "    data.append(np.max(untrained[~np.isnan(untrained)]))\n",
    "    print(x.title,F1_scores_mean[i],F1_scores_center[i],F1_scores_trained[i],perc_scored[i])\n",
    "    all_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labMT', 100.0, array([[ 739.,  261.],\n",
       "        [ 471.,  529.]]), 0.62991986652847642, array([[ 1000.,     0.],\n",
       "        [ 1000.,     0.]]), nan, array([[ 595.,  307.],\n",
       "        [ 347.,  556.]]), 0.63750389988773248, 0.62991986652847642]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OL 100.0 0.699781320057 0.705065204738\n",
      "1 & OL & 100 & 0.70 & 0.71\\\\\n",
      "HashtagSent 100.0 0.665536836052 0.663998655995\n",
      "2 & HashtagSent & 100 & 0.67 & 0.66\\\\\n",
      "MPQA 100.0 0.665380710101 0.658181208777\n",
      "3 & MPQA & 100 & 0.67 & 0.66\\\\\n",
      "SentiWordNet 100.0 0.650734596721 0.650261839477\n",
      "4 & SentiWordNet & 100 & 0.65 & 0.65\\\\\n",
      "labMT 100.0 0.637503899888 0.629919866528\n",
      "5 & labMT & 100 & 0.64 & 0.63\\\\\n",
      "AFINN 100.0 0.66768085522 0.625528058889\n",
      "6 & AFINN & 100 & 0.67 & 0.63\\\\\n",
      "Umigon 100.0 0.649815396481 0.621613114218\n",
      "7 & Umigon & 100 & 0.65 & 0.62\\\\\n",
      "GI 100.0 0.652727020429 0.605447902394\n",
      "8 & GI & 100 & 0.65 & 0.61\\\\\n",
      "SOCAL 100.0 0.714559506545 0.601253000571\n",
      "9 & SOCAL & 100 & 0.71 & 0.60\\\\\n",
      "VADER 100.0 0.672703267686 0.599666318733\n",
      "10 & VADER & 100 & 0.67 & 0.60\\\\\n",
      "WDAL 100.0 0.601152324771 0.590346760158\n",
      "11 & WDAL & 100 & 0.60 & 0.59\\\\\n",
      "SentiStrength 100.0 0.630811212872 0.580727106681\n",
      "12 & SentiStrength & 100 & 0.63 & 0.58\\\\\n",
      "EmoLex 100.0 0.653740550145 0.560225623373\n",
      "13 & EmoLex & 100 & 0.65 & 0.56\\\\\n",
      "LIWC15 100.0 0.636741695243 0.549891675027\n",
      "14 & LIWC15 & 100 & 0.64 & 0.55\\\\\n",
      "LIWC01 100.0 0.645691766445 0.544627923611\n",
      "15 & LIWC01 & 100 & 0.65 & 0.54\\\\\n",
      "LIWC07 100.0 0.640249712261 0.532206353833\n",
      "16 & LIWC07 & 100 & 0.64 & 0.53\\\\\n",
      "Pattern 100.0 0.730422014041 0.523611688132\n",
      "17 & Pattern & 100 & 0.73 & 0.52\\\\\n",
      "PANAS-X 32.7 0.511434285466 0.510897435897\n",
      "18 & PANAS-X & 33 & 0.51 & 0.51\\\\\n",
      "Sent140Lex 100.0 0.680427012431 0.466282005049\n",
      "19 & Sent140Lex & 100 & 0.68 & 0.47\\\\\n",
      "SenticNet 100.0 0.618809779191 0.448012605907\n",
      "20 & SenticNet & 100 & 0.62 & 0.45\\\\\n",
      "ANEW 100.0 0.567952391448 0.362478874595\n",
      "21 & ANEW & 100 & 0.57 & 0.36\\\\\n",
      "MaxDiff 100.0 0.659031265346 0.355277720844\n",
      "22 & MaxDiff & 100 & 0.66 & 0.36\\\\\n",
      "EmoSenticNet 100.0 0.579167606919 0.338864940739\n",
      "23 & EmoSenticNet & 100 & 0.58 & 0.34\\\\\n",
      "WK 100.0 0.626451835231 0.335551711787\n",
      "24 & WK & 100 & 0.63 & 0.34\\\\\n",
      "Emoticons 0.05 nan 0.0\n",
      "25 & Emoticons & 0 & -- & --\\\\\n",
      "USent 40.15 nan 0.0\n",
      "26 & USent & 40 & -- & --\\\\\n"
     ]
    }
   ],
   "source": [
    "f = open(\"tables/movie-review-accuracy-untrained-perf-sorted.tex\",\"w\")\n",
    "f.write(r\"\\begin{tabular}{l | l | c | c | c |}\")\n",
    "f.write(\"\\n\")\n",
    "f.write(r\"Rank & Title & \\% Scored & F1 Trained & F1 Untrained\\\\\")\n",
    "f.write(\"\\n\")\n",
    "f.write(r\"\\hline\")\n",
    "f.write(\"\\n\")\n",
    "for i,x in enumerate(sorted(all_data,key=lambda x: x[-1],reverse=True)):\n",
    "    print(x[0],x[1],x[-2],x[-1])\n",
    "    if np.isnan(x[-2]):\n",
    "        x[-2] = \"--\"\n",
    "    else:\n",
    "        x[-2] = \"{0:.2f}\".format(x[-2])\n",
    "    if x[-1] == 0:\n",
    "        x[-1] = \"--\"\n",
    "    else:\n",
    "        x[-1] = \"{0:.2f}\".format(x[-1])\n",
    "    f.write(r\"{0}. & {1} & {2:.0f} & {3} & {4}\\\\\".format(i+1,x[0],x[1],x[-2],x[-1]))\n",
    "    print(r\"{0} & {1} & {2:.0f} & {3} & {4}\\\\\".format(i+1,x[0],x[1],x[-2],x[-1]))\n",
    "    f.write(\"\\n\")\n",
    "f.write(r\"\\end{tabular}\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sampleReviewsDictSentences(numReviews,numSamples,filelist,wordsRE):\n",
    "    \"\"\"Sample from all of the review.\"\"\"\n",
    "    if numReviews == 1:\n",
    "        choose_randomly = False\n",
    "    else:\n",
    "        choose_randomly = True\n",
    "\n",
    "    scores = [[] for j in range(len(wordsRE))]\n",
    "    for i in range(numSamples):\n",
    "        file = filelist[i]\n",
    "        ########################################\n",
    "        # this loads the files\n",
    "        f = open(file+\".txt\",\"r\")\n",
    "        rawtext = f.read()\n",
    "        f.close()\n",
    "        # add to the full dict\n",
    "        sentences = [x for x in rawtext.split(\"\\n\") if len(x) > 0]\n",
    "        sentence_dicts = [dictify(listify(x)) for x in sentences]\n",
    "        # print(len(sentences))\n",
    "        # for s in sentences:\n",
    "        #    print(s)\n",
    "        for j in range(len(wordsRE)):\n",
    "            for sentence_dict in sentence_dicts:\n",
    "                scores[j].append(wordsRE[j].score(sentence_dict,center=1000.0))\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_scores = sampleReviewsDictSentences(1,1000,pos_files,all_senti_dicts)\n",
    "neg_scores = sampleReviewsDictSentences(1,1000,neg_files,all_senti_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32937"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 19210.  13595.]\n",
      " [ 15699.  15870.]]\n",
      "[ 0.58558147  0.50270835]\n",
      "[ 0.55028789  0.53860512]\n",
      "[ 0.56738636  0.52003801]\n",
      "[[ 30832.   1956.]\n",
      " [ 28833.   2717.]]\n",
      "[ 0.94034403  0.08611727]\n",
      "[ 0.51675186  0.58142521]\n",
      "[ 0.66697673  0.15001518]\n",
      "[[ 16281.  13449.]\n",
      " [ 13201.  15326.]]\n",
      "[ 0.54762866  0.53724542]\n",
      "[ 0.55223526  0.53261512]\n",
      "[ 0.54992231  0.53492025]\n",
      "[ 0.40849596  0.54371219  0.        ]\n",
      "[ 0.40849596  0.54371219  0.        ]\n",
      "labMT 0.54371218594 0.408495958924 0.542421280078 99.4653893696\n",
      "[[ 17054.   4502.]\n",
      " [ 14963.   4577.]]\n",
      "[ 0.79114864  0.23423746]\n",
      "[ 0.53265453  0.50413041]\n",
      "[ 0.63666399  0.31985744]\n",
      "[[ 17540.   4001.]\n",
      " [ 15444.   4088.]]\n",
      "[ 0.81426118  0.20929756]\n",
      "[ 0.53177298  0.50537767]\n",
      "[ 0.6433746   0.29600666]\n",
      "[[ 12028.   7487.]\n",
      " [ 10133.   7499.]]\n",
      "[ 0.6163464   0.42530626]\n",
      "[ 0.54275529  0.50040037]\n",
      "[ 0.5772147   0.45980747]\n",
      "[ 0.46969063  0.47826071  0.        ]\n",
      "[ 0.46969063  0.47826071  0.        ]\n",
      "ANEW 0.478260714278 0.469690630203 0.518511086088 63.4981458591\n",
      "[[ 28124.   4018.]\n",
      " [ 25510.   5004.]]\n",
      "[ 0.87499222  0.1639903 ]\n",
      "[ 0.52436887  0.5546442 ]\n",
      "[ 0.65575452  0.25313638]\n",
      "[[ 28551.   3575.]\n",
      " [ 26033.   4465.]]\n",
      "[ 0.88871942  0.14640304]\n",
      "[ 0.52306537  0.55534826]\n",
      "[ 0.65853996  0.23171934]\n",
      "[[ 16606.  12553.]\n",
      " [ 13621.  13957.]]\n",
      "[ 0.56949827  0.50609181]\n",
      "[ 0.54937639  0.52648057]\n",
      "[ 0.55925639  0.5160849 ]\n",
      "[ 0.44512965  0.45444545  0.        ]\n",
      "[ 0.44512965  0.45444545  0.        ]\n",
      "WK 0.454445452721 0.445129651369 0.537670644539 96.8108776267\n",
      "[[ 23321.   7572.]\n",
      " [ 20030.   9245.]]\n",
      "[ 0.75489593  0.31579846]\n",
      "[ 0.5379576   0.54974133]\n",
      "[ 0.62822585  0.40115421]\n",
      "[[ 14353.  10170.]\n",
      " [ 10820.  11933.]]\n",
      "[ 0.58528728  0.52445831]\n",
      "[ 0.57017439  0.53988146]\n",
      "[ 0.577632    0.53205814]\n",
      "[[ 13078.  14963.]\n",
      " [  9760.  16670.]]\n",
      "[ 0.4663885   0.63072266]\n",
      "[ 0.57264209  0.52698132]\n",
      "[ 0.51408243  0.57420388]\n",
      "[ 0.55484507  0.51469003  0.        ]\n",
      "[ 0.55484507  0.51469003  0.        ]\n",
      "MPQA 0.514690031606 0.554845072092 0.544143156428 92.9666254635\n",
      "[[ 27333.   5317.]\n",
      " [ 24750.   6545.]]\n",
      "[ 0.83715161  0.20913884]\n",
      "[ 0.52479696  0.55176193]\n",
      "[ 0.64515596  0.30331117]\n",
      "[[ 12140.   5563.]\n",
      " [  9296.   6779.]]\n",
      "[ 0.68575948  0.42171073]\n",
      "[ 0.566337    0.54926268]\n",
      "[ 0.6203531   0.47710877]\n",
      "[[ 10962.  18622.]\n",
      " [  8350.  19898.]]\n",
      "[ 0.37053813  0.70440385]\n",
      "[ 0.56762635  0.51656282]\n",
      "[ 0.44838024  0.59603403]\n",
      "[ 0.54873094  0.47423356  0.        ]\n",
      "[ 0.54873094  0.47423356  0.        ]\n",
      "LIWC01 0.474233563347 0.548730936703 0.52220713194 98.8025339926\n",
      "[[ 26505.   6224.]\n",
      " [ 23832.   7617.]]\n",
      "[ 0.80983226  0.24220166]\n",
      "[ 0.52655105  0.55032151]\n",
      "[ 0.63816724  0.33636564]\n",
      "[[ 13600.   6269.]\n",
      " [ 10543.   7668.]]\n",
      "[ 0.68448337  0.42106419]\n",
      "[ 0.56331028  0.55019014]\n",
      "[ 0.61801327  0.47704367]\n",
      "[[ 12343.  17310.]\n",
      " [  9501.  18902.]]\n",
      "[ 0.41624793  0.66549308]\n",
      "[ 0.56505219  0.52198166]\n",
      "[ 0.47936773  0.58506539]\n",
      "[ 0.54752847  0.48726644  0.        ]\n",
      "[ 0.54752847  0.48726644  0.        ]\n",
      "LIWC07 0.487266442069 0.54752847106 0.532216558727 99.1625463535\n",
      "[[ 26406.   6338.]\n",
      " [ 23588.   7887.]]\n",
      "[ 0.80643782  0.25057983]\n",
      "[ 0.52818338  0.5544464 ]\n",
      "[ 0.63830404  0.34516411]\n",
      "[[ 13413.   6346.]\n",
      " [ 10331.   7898.]]\n",
      "[ 0.6788299   0.43326568]\n",
      "[ 0.56490061  0.55447908]\n",
      "[ 0.61664713  0.48643488]\n",
      "[[ 12208.  17463.]\n",
      " [  9366.  19061.]]\n",
      "[ 0.41144552  0.6705245 ]\n",
      "[ 0.56586632  0.52187603]\n",
      "[ 0.47645624  0.58693477]\n",
      "[ 0.55154101  0.49173408  0.        ]\n",
      "[ 0.55154101  0.49173408  0.        ]\n",
      "LIWC15 0.491734078938 0.551541006075 0.531695502921 99.2258961681\n",
      "[[ 17883.   7579.]\n",
      " [ 13938.   9750.]]\n",
      "[ 0.70234074  0.41160081]\n",
      "[ 0.56198737  0.56264066]\n",
      "[ 0.62437372  0.47541263]\n",
      "[[ 12278.   9334.]\n",
      " [  8443.  11604.]]\n",
      "[ 0.56811031  0.57883973]\n",
      "[ 0.59253897  0.55420766]\n",
      "[ 0.58006756  0.56625595]\n",
      "[[ 14621.   8459.]\n",
      " [ 10904.  10449.]]\n",
      "[ 0.6334922   0.48934576]\n",
      "[ 0.57281097  0.55262323]\n",
      "[ 0.60162535  0.51906311]\n",
      "[ 0.57316175  0.54989318  0.        ]\n",
      "[ 0.57316175  0.54989318  0.        ]\n",
      "OL 0.549893178615 0.573161753442 0.560344230186 75.9425216316\n",
      "[[ 400.  143.]\n",
      " [ 261.  131.]]\n",
      "[ 0.73664825  0.33418367]\n",
      "[ 0.60514372  0.47810219]\n",
      "[ 0.66445183  0.39339339]\n",
      "[[ 400.  143.]\n",
      " [ 261.  131.]]\n",
      "[ 0.73664825  0.33418367]\n",
      "[ 0.60514372  0.47810219]\n",
      "[ 0.66445183  0.39339339]\n",
      "[[ 369.  124.]\n",
      " [ 243.  116.]]\n",
      "[ 0.7484787   0.32311978]\n",
      "[ 0.60294118  0.48333333]\n",
      "[ 0.6678733   0.38731219]\n",
      "[ 0.52892261  0.52892261  0.        ]\n",
      "[ 0.52892261  0.52892261  0.        ]\n",
      "PANAS-X 0.528922610318 0.528922610318 0.527592745073 1.44468479604\n",
      "[[ 20582.   6756.]\n",
      " [ 16299.   8827.]]\n",
      "[ 0.75287146  0.3513094 ]\n",
      "[ 0.55806513  0.56645062]\n",
      "[ 0.6409941   0.43366332]\n",
      "[[ 17653.   6955.]\n",
      " [ 13504.   9043.]]\n",
      "[ 0.71736834  0.40107331]\n",
      "[ 0.56658215  0.56525816]\n",
      "[ 0.63312113  0.4692178 ]\n",
      "[[ 13747.  11039.]\n",
      " [ 10090.  12585.]]\n",
      "[ 0.55462761  0.55501654]\n",
      "[ 0.57670848  0.53272096]\n",
      "[ 0.56545256  0.54364025]\n",
      "[ 0.55116947  0.53732871  0.        ]\n",
      "[ 0.55116947  0.53732871  0.        ]\n",
      "Pattern 0.537328708007 0.551169465354 0.554546407505 81.0630407911\n",
      "[[ 21999.  10777.]\n",
      " [ 19161.  12315.]]\n",
      "[ 0.67119234  0.39125048]\n",
      "[ 0.53447522  0.53330158]\n",
      "[ 0.59508223  0.45136344]\n",
      "[[ 18396.  13972.]\n",
      " [ 15443.  15410.]]\n",
      "[ 0.5683391   0.49946521]\n",
      "[ 0.54363309  0.52447076]\n",
      "[ 0.55571163  0.51166265]\n",
      "[[ 16526.  13183.]\n",
      " [ 13729.  14689.]]\n",
      "[ 0.55626241  0.5168907 ]\n",
      "[ 0.54622376  0.52701636]\n",
      "[ 0.55119739  0.52190442]\n",
      "[ 0.53368714  0.52322283  0.        ]\n",
      "[ 0.53368714  0.52322283  0.        ]\n",
      "SentiWordNet 0.523222834865 0.533687143152 0.536550904309 99.2768850433\n",
      "[[ 16082.   7162.]\n",
      " [ 12963.   8904.]]\n",
      "[ 0.69187747  0.40718891]\n",
      "[ 0.55369255  0.55421387]\n",
      "[ 0.61511981  0.46945931]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py:32: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py:37: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 13691.   8218.]\n",
      " [ 10396.  10107.]]\n",
      "[ 0.62490301  0.49295225]\n",
      "[ 0.56839789  0.55154161]\n",
      "[ 0.59531264  0.52060369]\n",
      "[[ 12271.   8820.]\n",
      " [  9235.  10488.]]\n",
      "[ 0.58181215  0.53176494]\n",
      "[ 0.57058495  0.54319453]\n",
      "[ 0.57614386  0.53741897]\n",
      "[ 0.55795816  0.54228956  0.        ]\n",
      "[ 0.55795816  0.54228956  0.        ]\n",
      "AFINN 0.542289562355 0.557958161971 0.556781417279 69.7017923362\n",
      "[[ 18459.   8274.]\n",
      " [ 15181.   9924.]]\n",
      "[ 0.69049489  0.39529974]\n",
      "[ 0.54872176  0.54533465]\n",
      "[ 0.61149852  0.45835162]\n",
      "[[ 14146.   8278.]\n",
      " [ 10856.   9928.]]\n",
      "[ 0.63084196  0.47767513]\n",
      "[ 0.56579474  0.54531473]\n",
      "[ 0.59655042  0.50925878]\n",
      "[[ 12812.  11414.]\n",
      " [  9770.  12887.]]\n",
      "[ 0.5288533   0.56878669]\n",
      "[ 0.56735453  0.53030739]\n",
      "[ 0.54742779  0.54887346]\n",
      "[ 0.5529046   0.53492507  0.        ]\n",
      "[ 0.5529046   0.53492507  0.        ]\n",
      "GI 0.534925066455 0.552904599844 0.548150625756 80.0957972806\n",
      "[[ 17732.  14995.]\n",
      " [ 15159.  16254.]]\n",
      "[ 0.54181563  0.51742909]\n",
      "[ 0.53911404  0.52014464]\n",
      "[ 0.54046146  0.51878331]\n",
      "[[ 32585.    125.]\n",
      " [ 31119.    255.]]\n",
      "[ 0.99617854  0.00812775]\n",
      "[ 0.51150634  0.67105263]\n",
      "[ 0.67593918  0.01606097]\n",
      "[[ 14831.  14828.]\n",
      " [ 12582.  15804.]]\n",
      "[ 0.50005057  0.55675333]\n",
      "[ 0.54102068  0.51593105]\n",
      "[ 0.51972946  0.53556542]\n",
      "[ 0.34600007  0.52962239  0.        ]\n",
      "[ 0.34600007  0.52962239  0.        ]\n",
      "WDAL 0.529622386199 0.346000073827 0.527647442628 99.1038318912\n",
      "[[  1244.  31611.]\n",
      " [   882.  30780.]]\n",
      "[ 0.03786334  0.97214326]\n",
      "[ 0.58513641  0.49334039]\n",
      "[ 0.07112432  0.65452458]\n",
      "[[ 22856.   9998.]\n",
      " [ 18983.  12679.]]\n",
      "[ 0.69568393  0.40044849]\n",
      "[ 0.54628457  0.55911276]\n",
      "[ 0.61199845  0.46666299]\n",
      "[[ 16700.  13093.]\n",
      " [ 13035.  15581.]]\n",
      "[ 0.56053435  0.5444856 ]\n",
      "[ 0.56162771  0.54338425]\n",
      "[ 0.5610805   0.54393437]\n",
      "[ 0.53933072  0.36282445  0.        ]\n",
      "[ 0.53933072  0.36282445  0.        ]\n",
      "Sent140Lex 0.362824450601 0.539330716523 0.552507434466 99.6863411619\n",
      "[[ 22217.   5325.]\n",
      " [ 19707.   6588.]]\n",
      "[ 0.80665892  0.25054193]\n",
      "[ 0.52993512  0.55300932]\n",
      "[ 0.63965105  0.34484925]\n",
      "[[ 22228.   5076.]\n",
      " [ 19715.   6311.]]\n",
      "[ 0.81409317  0.24248828]\n",
      "[ 0.52995732  0.55422851]\n",
      "[ 0.64199171  0.33736936]\n",
      "[[ 13952.  11045.]\n",
      " [ 11437.  12332.]]\n",
      "[ 0.55814698  0.51882704]\n",
      "[ 0.54952932  0.52752706]\n",
      "[ 0.55380463  0.52314088]\n",
      "[ 0.48968054  0.49225015  0.        ]\n",
      "[ 0.48968054  0.49225015  0.        ]\n",
      "MaxDiff 0.492250149272 0.489680537211 0.538472754893 83.184487021\n",
      "[[ 12318.  20533.]\n",
      " [  8862.  22783.]]\n",
      "[ 0.37496575  0.71995576]\n",
      "[ 0.5815864   0.52597193]\n",
      "[ 0.45596047  0.60786276]\n",
      "[[ 17718.  15131.]\n",
      " [ 13734.  17909.]]\n",
      "[ 0.53937715  0.56597036]\n",
      "[ 0.56333461  0.54203995]\n",
      "[ 0.55109563  0.55374673]\n",
      "[[ 16607.  13156.]\n",
      " [ 12873.  15702.]]\n",
      "[ 0.55797467  0.54950131]\n",
      "[ 0.56333107  0.54411255]\n",
      "[ 0.56064008  0.54679366]\n",
      "[ 0.55242118  0.53191161  0.        ]\n",
      "[ 0.55242118  0.53191161  0.        ]\n",
      "HashtagSent 0.531911611219 0.552421181223 0.553716865418 99.6538936959\n",
      "[[ 24506.   7220.]\n",
      " [ 21191.   8713.]]\n",
      "[ 0.7724264  0.2913657]\n",
      "[ 0.53627153  0.54685244]\n",
      "[ 0.63304186  0.38017322]\n",
      "[[ 14818.   7288.]\n",
      " [ 11389.   8782.]]\n",
      "[ 0.67031575  0.43537752]\n",
      "[ 0.56542145  0.54648413]\n",
      "[ 0.61341668  0.48464446]\n",
      "[[ 13307.  15433.]\n",
      " [ 10208.  16769.]]\n",
      "[ 0.46301322  0.62160359]\n",
      "[ 0.56589411  0.52074405]\n",
      "[ 0.50931011  0.5667213 ]\n",
      "[ 0.54903057  0.50660754  0.        ]\n",
      "[ 0.54903057  0.50660754  0.        ]\n",
      "EmoLex 0.506607541726 0.549030571097 0.538015708515 95.2255871446\n",
      "[[ 21202.   8363.]\n",
      " [ 16803.  10892.]]\n",
      "[ 0.71713174  0.39328399]\n",
      "[ 0.55787396  0.56567125]\n",
      "[ 0.62755661  0.46398296]\n",
      "[[ 19924.   8966.]\n",
      " [ 15471.  11538.]]\n",
      "[ 0.6896504   0.42719094]\n",
      "[ 0.56290437  0.56271947]\n",
      "[ 0.61986467  0.4856776 ]\n",
      "[[ 15218.  11558.]\n",
      " [ 11413.  13632.]]\n",
      "[ 0.56834479  0.54430026]\n",
      "[ 0.5714393   0.54116713]\n",
      "[ 0.56988784  0.54272917]\n",
      "[ 0.55277113  0.54576978  0.        ]\n",
      "[ 0.55277113  0.54576978  0.        ]\n",
      "SOCAL 0.545769784279 0.552771134594 0.556308507653 88.4734239802\n",
      "[[ 23294.   8840.]\n",
      " [ 20545.   9966.]]\n",
      "[ 0.72490197  0.3266363 ]\n",
      "[ 0.53135336  0.52993725]\n",
      "[ 0.61321785  0.40416084]\n",
      "[[ 21744.  10386.]\n",
      " [ 19037.  11467.]]\n",
      "[ 0.6767507   0.37591791]\n",
      "[ 0.53318948  0.52473345]\n",
      "[ 0.59645321  0.43803121]\n",
      "[[ 15322.  13829.]\n",
      " [ 13000.  14547.]]\n",
      "[ 0.52560804  0.52807928]\n",
      "[ 0.54099287  0.51265154]\n",
      "[ 0.5331895   0.52025106]\n",
      "[ 0.51724221  0.50868935  0.        ]\n",
      "[ 0.51724221  0.50868935  0.        ]\n",
      "SenticNet 0.508689345373 0.517242209447 0.526720278585 96.793881335\n",
      "[[ 0.  0.]\n",
      " [ 1.  0.]]\n",
      "[ nan   0.]\n",
      "[  0.  nan]\n",
      "[ nan  nan]\n",
      "[[ 0.  0.]\n",
      " [ 1.  0.]]\n",
      "[ nan   0.]\n",
      "[  0.  nan]\n",
      "[ nan  nan]\n",
      "[[ 0.  0.]\n",
      " [ 0.  0.]]\n",
      "[ nan  nan]\n",
      "[ nan  nan]\n",
      "[ nan  nan]\n",
      "[ nan  nan   0.]\n",
      "[ 0.]\n",
      "Emoticons nan nan nan 0.00154511742892\n",
      "[[ 17273.   8234.]\n",
      " [ 14729.   9376.]]\n",
      "[ 0.67718665  0.38896495]\n",
      "[ 0.53974752  0.53242476]\n",
      "[ 0.60070598  0.44952655]\n",
      "[[ 11076.  12819.]\n",
      " [  8482.  14107.]]\n",
      "[ 0.46352793  0.6245075 ]\n",
      "[ 0.56631557  0.5239174 ]\n",
      "[ 0.50979219  0.56980713]\n",
      "[[ 11837.  11334.]\n",
      " [  9293.  12467.]]\n",
      "[ 0.51085408  0.57293199]\n",
      "[ 0.56019877  0.52380152]\n",
      "[ 0.53438974  0.5472663 ]\n",
      "[ 0.53979966  0.52511626  0.        ]\n",
      "[ 0.53979966  0.52511626  0.        ]\n",
      "SentiStrength 0.525116262829 0.539799659207 0.540828022608 76.6563658838\n",
      "[[ 17818.   8466.]\n",
      " [ 14261.  10348.]]\n",
      "[ 0.67790291  0.42049657]\n",
      "[ 0.55544125  0.55001595]\n",
      "[ 0.61059233  0.47661378]\n",
      "[[ 17013.   9144.]\n",
      " [ 13288.  11182.]]\n",
      "[ 0.65041863  0.45696772]\n",
      "[ 0.56146662  0.55013283]\n",
      "[ 0.6026781  0.499241 ]\n",
      "[[ 13935.   9913.]\n",
      " [ 10544.  11695.]]\n",
      "[ 0.58432573  0.52587796]\n",
      "[ 0.56926345  0.54123473]\n",
      "[ 0.57669626  0.53344585]\n",
      "[ 0.55095955  0.54360305  0.        ]\n",
      "[ 0.55095955  0.54360305  0.        ]\n",
      "VADER 0.54360305172 0.550959550327 0.555071051266 78.6356613103\n",
      "[[ 9680.  7919.]\n",
      " [ 7354.  9500.]]\n",
      "[ 0.55003125  0.56366441]\n",
      "[ 0.56827521  0.54538148]\n",
      "[ 0.55900442  0.55437225]\n",
      "[[ 7438.  7959.]\n",
      " [ 5308.  9539.]]\n",
      "[ 0.48308112  0.6424867 ]\n",
      "[ 0.58355563  0.54514802]\n",
      "[ 0.52858615  0.58982841]\n",
      "[[ 8794.  7226.]\n",
      " [ 6566.  8613.]]\n",
      "[ 0.54893883  0.56742868]\n",
      "[ 0.57252604  0.54378433]\n",
      "[ 0.56048438  0.55535496]\n",
      "[ 0.55920728  0.55668833  0.        ]\n",
      "[ 0.55920728  0.55668833  0.        ]\n",
      "Umigon 0.556688332063 0.559207280869 0.557919670073 53.2339307787\n",
      "[[   0.  694.]\n",
      " [   0.  857.]]\n",
      "[ 0.  1.]\n",
      "[        nan  0.55254674]\n",
      "[        nan  0.71179402]\n",
      "[[   0.  694.]\n",
      " [   0.  857.]]\n",
      "[ 0.  1.]\n",
      "[        nan  0.55254674]\n",
      "[        nan  0.71179402]\n",
      "[[ 0.  0.]\n",
      " [ 0.  0.]]\n",
      "[ nan  nan]\n",
      "[ nan  nan]\n",
      "[ nan  nan]\n",
      "[ nan  nan   0.]\n",
      "[ 0.]\n",
      "USent nan nan nan 2.39647713226\n",
      "[[ 27148.   5143.]\n",
      " [ 24867.   5952.]]\n",
      "[ 0.84072962  0.19312762]\n",
      "[ 0.52192637  0.53645786]\n",
      "[ 0.64403483  0.28401012]\n",
      "[[ 31506.    228.]\n",
      " [ 29667.    324.]]\n",
      "[ 0.99281528  0.01080324]\n",
      "[ 0.51503114  0.58695652]\n",
      "[ 0.67822661  0.02121599]\n",
      "[[ 17961.  11290.]\n",
      " [ 16002.  11825.]]\n",
      "[ 0.61403029  0.42494699]\n",
      "[ 0.52884021  0.51157257]\n",
      "[ 0.5682602   0.46425346]\n",
      "[ 0.3497213   0.46402247  0.        ]\n",
      "[ 0.3497213   0.46402247  0.        ]\n",
      "EmoSenticNet 0.464022470734 0.349721302141 0.516256830125 97.5123609394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py:7: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/usr/local/lib/python3.5/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n",
      "/usr/local/lib/python3.5/site-packages/numpy/core/_methods.py:70: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py:42: RuntimeWarning: invalid value encountered in greater\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py:43: RuntimeWarning: invalid value encountered in less\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py:44: RuntimeWarning: invalid value encountered in greater\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py:45: RuntimeWarning: invalid value encountered in less\n"
     ]
    }
   ],
   "source": [
    "all_data = []\n",
    "for i,x in enumerate(all_senti_dicts):\n",
    "    data = [x.title]\n",
    "    conf_mat = np.zeros((2,2))\n",
    "    a = np.array(pos_scores[i])\n",
    "    # print(len(a[a==1000.0]),len(a[a!=1000.0]),len(a[(a!=1000.0) & (a>x.scorelist.mean())]))\n",
    "    conf_mat[0,0] = len(a[(a!=1000.0) & (a>x.scorelist.mean())])\n",
    "    conf_mat[0,1] = len(a[(a!=1000.0) & (a<x.scorelist.mean())])\n",
    "    a = np.array(neg_scores[i])\n",
    "    conf_mat[1,0] = len(a[(a!=1000.0) & (a>x.scorelist.mean())])\n",
    "    conf_mat[1,1] = len(a[(a!=1000.0) & (a<x.scorelist.mean())])\n",
    "    print(conf_mat)\n",
    "    F1_scores_mean[i] = classifier_perf(conf_mat)\n",
    "    perc_scored[i] = 100*conf_mat.sum()/(len(pos_scores[i])+len(neg_scores[i]))\n",
    "    data.append(perc_scored[i])\n",
    "    data.append(conf_mat)\n",
    "    data.append(F1_scores_mean[i])\n",
    "    conf_mat = np.zeros((2,2))\n",
    "    a = np.array(pos_scores[i])\n",
    "    conf_mat[0,0] = len(a[(a!=1000.0) & (a>x.center)])\n",
    "    conf_mat[0,1] = len(a[(a!=1000.0) & (a<x.center)])\n",
    "    a = np.array(neg_scores[i])\n",
    "    conf_mat[1,0] = len(a[(a!=1000.0) & (a>x.center)])\n",
    "    conf_mat[1,1] = len(a[(a!=1000.0) & (a<x.center)])\n",
    "    print(conf_mat)\n",
    "    F1_scores_center[i] = classifier_perf(conf_mat)\n",
    "    data.append(conf_mat)\n",
    "    data.append(F1_scores_center[i])\n",
    "    total_n_samples = len(pos_scores[i])+len(neg_scores[i])\n",
    "    # grab 100 pos reviews\n",
    "    a = np.array(pos_scores[i])\n",
    "    r = np.random.choice(np.arange(len(pos_scores[i])),size=.05*total_n_samples)\n",
    "    b = np.zeros(len(pos_scores[i]))\n",
    "    b[r] = 1\n",
    "    # grab 100 neg reviews\n",
    "    a_ = np.array(neg_scores[i])\n",
    "    r_ = np.random.choice(np.arange(len(neg_scores[i])),size=.05*total_n_samples)\n",
    "    b_ = np.zeros(len(neg_scores[i]))\n",
    "    b_[r_] = 1\n",
    "    avg = np.concatenate((a[(a!=1000.0) & (b>0)],a_[(a_!=1000.0) & (b_>0)])).mean()\n",
    "    conf_mat = np.zeros((2,2))\n",
    "    conf_mat[0,0] = len(a[(a!=1000.0) & (a>avg) & (b<1)])\n",
    "    conf_mat[0,1] = len(a[(a!=1000.0) & (a<avg) & (b<1)])\n",
    "    conf_mat[1,0] = len(a_[(a_!=1000.0) & (a_>avg) & (b_<1)])\n",
    "    conf_mat[1,1] = len(a_[(a_!=1000.0) & (a_<avg) & (b_<1)])\n",
    "    print(conf_mat)\n",
    "    F1_scores_trained[i] = classifier_perf(conf_mat)\n",
    "    data.append(conf_mat)\n",
    "    data.append(F1_scores_trained[i])\n",
    "    untrained = np.array([F1_scores_center[i],F1_scores_mean[i],0.0])\n",
    "    print(untrained)\n",
    "    print(untrained[~np.isnan(untrained)])\n",
    "    data.append(np.max(untrained[~np.isnan(untrained)]))\n",
    "    weighted_best = data[-1]*perc_scored[i]/100\n",
    "    data.append(weighted_best)\n",
    "    print(x.title,F1_scores_mean[i],F1_scores_center[i],F1_scores_trained[i],perc_scored[i])\n",
    "    all_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labMT', 99.465389369592089, array([[ 19210.,  13595.],\n",
       "        [ 15699.,  15870.]]), 0.54371218594004644, array([[ 30832.,   1956.],\n",
       "        [ 28833.,   2717.]]), 0.40849595892370738, array([[ 16281.,  13449.],\n",
       "        [ 13201.,  15326.]]), 0.54242128007822332, 0.54371218594004644, 0.54080544279518772]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. & HashtagSent & 100 & 0.55 & 0.55 & 0.55\\\\\n",
      "2. & LIWC15 & 99 & 0.53 & 0.55 & 0.55\\\\\n",
      "3. & LIWC07 & 99 & 0.53 & 0.55 & 0.54\\\\\n",
      "4. & LIWC01 & 99 & 0.52 & 0.55 & 0.54\\\\\n",
      "5. & labMT & 99 & 0.54 & 0.54 & 0.54\\\\\n",
      "6. & Sent140Lex & 100 & 0.55 & 0.54 & 0.54\\\\\n",
      "7. & SentiWordNet & 99 & 0.54 & 0.53 & 0.53\\\\\n",
      "8. & WDAL & 99 & 0.53 & 0.53 & 0.52\\\\\n",
      "9. & EmoLex & 95 & 0.54 & 0.55 & 0.52\\\\\n",
      "10. & MPQA & 93 & 0.54 & 0.55 & 0.52\\\\\n",
      "11. & SenticNet & 97 & 0.53 & 0.52 & 0.50\\\\\n",
      "12. & SOCAL & 88 & 0.56 & 0.55 & 0.49\\\\\n",
      "13. & EmoSenticNet & 98 & 0.52 & 0.46 & 0.45\\\\\n",
      "14. & Pattern & 81 & 0.55 & 0.55 & 0.45\\\\\n",
      "15. & GI & 80 & 0.55 & 0.55 & 0.44\\\\\n",
      "16. & WK & 97 & 0.54 & 0.45 & 0.44\\\\\n",
      "17. & OL & 76 & 0.56 & 0.57 & 0.44\\\\\n",
      "18. & VADER & 79 & 0.56 & 0.55 & 0.43\\\\\n",
      "19. & SentiStrength & 77 & 0.54 & 0.54 & 0.41\\\\\n",
      "20. & MaxDiff & 83 & 0.54 & 0.49 & 0.41\\\\\n",
      "21. & AFINN & 70 & 0.56 & 0.56 & 0.39\\\\\n",
      "22. & ANEW & 63 & 0.52 & 0.48 & 0.30\\\\\n",
      "23. & Umigon & 53 & 0.56 & 0.56 & 0.30\\\\\n",
      "24. & PANAS-X & 1 & 0.53 & 0.53 & 0.01\\\\\n",
      "25. & Emoticons & 0 & -- & -- & --\\\\\n",
      "26. & USent & 2 & -- & -- & --\\\\\n"
     ]
    }
   ],
   "source": [
    "f = open(\"tables/movie-review-sentence-accuracy-untrained-perf-sorted.tex\",\"w\")\n",
    "f.write(r\"\\begin{tabular}{l | l | c | c | c | c }\")\n",
    "f.write(\"\\n\")\n",
    "f.write(r\"Rank & Title & \\% Scored & F1 Trained of Scored & F1 Untrained of Scored & F1 Untrained, All\\\\\")\n",
    "f.write(\"\\n\")\n",
    "f.write(r\"\\hline\")\n",
    "f.write(\"\\n\")\n",
    "for i,x in enumerate(sorted(all_data,key=lambda x: x[-1],reverse=True)):\n",
    "    if np.isnan(x[-3]):\n",
    "        x[-3] = \"--\"\n",
    "    else:\n",
    "        x[-3] = \"{0:.2f}\".format(x[-3])\n",
    "    if x[-2] == 0:\n",
    "        x[-2] = \"--\"\n",
    "    else:\n",
    "        x[-2] = \"{0:.2f}\".format(x[-2])\n",
    "    if x[-1] == 0:\n",
    "        x[-1] = \"--\"\n",
    "    else:\n",
    "        x[-1] = \"{0:.2f}\".format(x[-1])\n",
    "    # print(x[0],x[1],x[-2],x[-1])\n",
    "    f.write(r\"{0}. & {1} & {2:.0f} & {3} & {4} & {5}\\\\\".format(i+1,x[0],x[1],x[-3],x[-2],x[-1]))\n",
    "    print(r\"{0}. & {1} & {2:.0f} & {3} & {4} & {5}\\\\\".format(i+1,x[0],x[1],x[-3],x[-2],x[-1]))\n",
    "    f.write(\"\\n\")\n",
    "f.write(r\"\\end{tabular}\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_results = np.array([float(x[-1]) for x in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.54080544,  0.30368669,  0.43995263,  0.51582074,  0.54216007,\n",
       "        0.54294317,  0.54727151,  0.43527349,  0.00764126,  0.44679473,\n",
       "        0.52982797,  0.38890684,  0.44285335,  0.52487608,  0.53763906,\n",
       "        0.40947576,  0.55050922,  0.52281758,  0.48905555,  0.50065881,\n",
       "        0.        ,  0.4137908 ,  0.43325069,  0.29768802,  0.        ,\n",
       "        0.45247927])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41600687391234187"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44963699751497788"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
